---
title: "Homework 6"
author: "Ying Jin"
date: "2020/11/28"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(purrr)

set.seed(1)
```

## Problem 1

Import the dataset

```{r}
url_file = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicide_data = read_csv(url(url_file), na = c("", "NA", "Unknown"))
  
homicide_df =
  homicide_data %>% 
  mutate(
    city_state = str_c(city,state, sep = ", "),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest" ~ 0,
      disposition == "Closed by arrest" ~ 1,
    ) ,
    victim_age = as.numeric(victim_age)
  ) %>% 
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")),
         victim_race %in% c("Black","White")) %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

Start with one city

```{r}
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_sex + victim_race, 
    data = baltimore_df, 
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96*std.error),
    CI_upper = exp(estimate + 1.96*std.error)
  ) %>% 
  select(term, OR, starts_with("CI_")) %>% 
  knitr::kable()
```

Try this across cities

```{r}
models_results_df =
homicide_df %>% 
  nest(-city_state) %>% 
  mutate(
    models = map(.x = data, ~glm(resolution ~ victim_age + victim_sex + victim_race, 
    data = .x, 
    family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(-data, -models) %>% 
  unnest(results) %>% 
  mutate(
     OR = exp(estimate),
    CI_lower = exp(estimate - 1.96*std.error),
    CI_upper = exp(estimate + 1.96*std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI_"))
```

Make a plot

```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(
    city_state = fct_reorder(city_state, OR)
  ) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  theme(axis.text.x = element_text(angle = 70, hjust = 1))
```

## Problem 2

import dataset

```{r}
bwt_data = read_csv("./data/birthweight.csv")
```

tidy dataset

```{r}
bwt_df = 
bwt_data %>% 
  mutate(
    babysex = factor(case_when(
      babysex == 1 ~"male",
      babysex == 2 ~"female")),
    frace = factor(case_when(
      frace == 1 ~"White",
      frace == 2 ~"Black",
      frace == 3 ~"Asian",
      frace == 4 ~"Puerto Rican",
      frace == 8 ~"Other",
      frace == 9 ~"Unknown"
    )),
    malform = factor(case_when(
      malform == 0 ~"absent",
      malform == 1 ~"present"
    )),
    mrace = factor(case_when(
      mrace == 1 ~"White",
      mrace == 2 ~"Black",
      mrace == 3 ~"Asian",
      mrace == 4 ~"Puerto Rican",
      mrace == 8 ~"Other"
    ))
  ) %>% 
  mutate(
    frace = fct_relevel(frace,"White", "Black", "Asian", "Puerto Rican", "Other"),
    mrace = fct_relevel(mrace,"White", "Black", "Asian", "Puerto Rican"),
    babysex = fct_relevel(babysex, "male")
  )
```

inspect NAs

```{r}
bwt_df %>% 
  sapply(., function(x) sum(is.na(x)))
```

There is no NAs in this dataset

Then I try to build a linear model based on the dataset. I concentrate on mom's influence on their babies, so I mainly focus on predictors related to mothers.

A [study](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2974327/) shows there is consistent relationship between pregnancy weight gain and baby birth weight. Another [study](https://academic.oup.com/humrep/article/35/1/212/5713535) shows size at birth is strongly related to length of gestation. In addition, [a paper](https://www.nature.com/articles/pr2002265) reveals that maternal parity had a large influence on size at birth

Based on findings above, I build a model which examines the association between baby birth weight and mother’s weight gain during pregnancy, gestational age in weeks, as well as number of live births prior to this pregnancy.

```{r}
mod = lm(bwt ~ wtgain + gaweeks + parity, data = bwt_df)

broom::tidy(mod) %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)

bwt_df %>% 
  select(bwt, wtgain, gaweeks, parity) %>% 
  add_residuals(model = mod) %>% 
  add_predictions(model = mod) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = .4) +
  geom_smooth(method = "lm", se = F, color = "red")
  
```

Another two models:

* One using length at birth and gestational age as predictors (main effects only)

* Another using head circumference, length, sex, and all interactions (including the three-way interaction) between these

```{r}
mod_1 = lm(bwt ~ blength + gaweeks, data = bwt_df)

broom::tidy(mod_1) %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)

mod_2 = lm(bwt ~ bhead*blength*babysex, data = bwt_df)

broom::tidy(mod_2) %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)
```

Then I conduct cross validation. Firstly, split the dataset into train and test datasets.

```{r}
cv_df = crossv_mc(bwt_df, 100)
```

Fit models and obtain RMSE

```{r}
cv_df =
cv_df %>% 
  mutate(
    linear_mod_1 = map(.x = train, ~lm(bwt ~ wtgain + gaweeks + parity, data = .x)),
    linear_mod_2 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    linear_mod_3 = map(.x = train, ~lm(bwt ~  bhead*blength*babysex, data = .x))
  ) %>% 
  mutate(
    rmse_mod_1 = map2_dbl(.x = linear_mod_1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_mod_2 = map2_dbl(.x = linear_mod_2, .y = test, ~rmse(model = .x, data = .y)),
    rmse_mod_3 = map2_dbl(.x = linear_mod_3, .y = test, ~rmse(model = .x, data = .y))
    ) 
  
```
  
Make plots for comparison  
  
```{r}
cv_df %>% 
  select(starts_with("rmse_")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    names_prefix = "rmse_",
    values_to = "rmse"
  ) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin()
```

Based on th plot, model 3 has the lowest **RMSE** and model 1 has the highest **RMSE**.

## Problem 3

Import the dataset

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Make plot of tmax vs. tmin

```{r}
weather_df %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_point() +
  geom_smooth(method = "lm")
```

According to this plot, the points representing lower t_min and lower t_max distributed more disperse around the fitted line.

Use `bootstrap` function to conduct repeated sampling and do analysis

```{r}
weather_boot_results =
weather_df %>% 
  modelr::bootstrap(n = 5000, id = "strap_number") %>% 
  mutate(
    models = map(.x = strap, ~lm(tmax ~ tmin, data = .x)),
    results_glance = map(models, broom::glance),
    results_tidy = map(models, broom::tidy)
  ) %>% 
  select(strap_number, results_glance, results_tidy) %>% 
  unnest(results_glance, results_tidy) %>% 
  select(strap_number, r.squared, term, estimate) %>% 
  pivot_wider(
    everything(),
    names_from = term,
    values_from = estimate
  ) %>% 
  mutate(
    log_estimate_multi = log(`(Intercept)`*tmin)
  ) %>% 
  select(-`(Intercept)`, -tmin)
```

Make plot to see the distribution of r^2 

```{r}
weather_boot_results %>% 
  ggplot(aes(x = r.squared)) +
  geom_density() +
  labs(
    x = "r-square",
    title = "Distribution of R-Square"
  )
```

From the plot above we can see that the distribution of r^2 is a little left-skewed. Combined with the plot of tmax vs. tmin, I think that's because some samples were drawn from points with lower t_min and lower t_max, which have larger residuals compared to other points. 

And make another plot to see the distribution of log(β_0∗β_1)

```{r}
weather_boot_results %>% 
  ggplot(aes(x = log_estimate_multi)) +
  geom_density() +
  labs(
    x = "log(β_0 \* β_1)",
    title = "Distribution of Log(β_0 \* β_1)"
  )
```

Based on this plot, we can find that the distribution of log(β_0∗β_1) is also a little left-skewed. And the reason for it is the same as that for the distribution of r^2.

Next, construct 95% CI for r^2 and log(β_0∗β_1)

```{r}
weather_boot_results %>% 
  pivot_longer(
    r.squared:log_estimate_multi,
    names_to = "term",
    values_to = "estimate"
  ) %>% 
  group_by(term) %>% 
  summarise(
    CI_lower = quantile(estimate, 0.025),
    CI_upper = quantile(estimate, 0.975)
  ) 
```

The 95% CI for r^2 is (0.894, 0.927) and log(β_0∗β_1) is (1.97, 2.06).